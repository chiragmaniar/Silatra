{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand sign classification\n",
    "### The method of fragmentation\n",
    "\n",
    "The image is divided into blocks of 20x20. In each block, we calculate the area of contour lying in that block and divide it by the area of that block. If there is no contour, the area is simply zero.\n",
    "\n",
    "This calculation is performed 400 times and we get 400 features for a single image. \n",
    "\n",
    "These features are now trained using the classifiers:\n",
    "* Deep Learning Neural Network\n",
    "* KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data parsed: 19599\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data = pd.read_csv('new_data.csv')\n",
    "print('Total data parsed: %d'%(len(data)))\n",
    "\n",
    "no_of_classes = 36\n",
    "label_indexes = {}\n",
    "for i in range(10): label_indexes[i] = str(i)\n",
    "for i in range(26):\n",
    "    if not chr(ord('a')+i) in ['h','j','v']: label_indexes[10+i] = chr(ord('a')+i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 745\n",
      "Train on 9603 samples, validate on 4116 samples\n",
      "Epoch 1/7\n",
      "9603/9603 [==============================] - 12s 1ms/step - loss: 0.5044 - acc: 0.8679 - val_loss: 0.1265 - val_acc: 0.9670\n",
      "Epoch 2/7\n",
      "9603/9603 [==============================] - 11s 1ms/step - loss: 0.1080 - acc: 0.9677 - val_loss: 0.0824 - val_acc: 0.9772\n",
      "Epoch 3/7\n",
      "9603/9603 [==============================] - 11s 1ms/step - loss: 0.0599 - acc: 0.9824 - val_loss: 0.0601 - val_acc: 0.9835\n",
      "Epoch 4/7\n",
      "9603/9603 [==============================] - 12s 1ms/step - loss: 0.0421 - acc: 0.9863 - val_loss: 0.0573 - val_acc: 0.9845\n",
      "Epoch 5/7\n",
      "9603/9603 [==============================] - 12s 1ms/step - loss: 0.0369 - acc: 0.9892 - val_loss: 0.0679 - val_acc: 0.9779\n",
      "Epoch 6/7\n",
      "9603/9603 [==============================] - 12s 1ms/step - loss: 0.0300 - acc: 0.9908 - val_loss: 0.0392 - val_acc: 0.9898\n",
      "Epoch 7/7\n",
      "9603/9603 [==============================] - 13s 1ms/step - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0496 - val_acc: 0.9859\n",
      "5880/5880 [==============================] - 1s 176us/step\n",
      "\n",
      "acc: 98.50%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.utils import np_utils\n",
    "from random import randint\n",
    "\n",
    "X = data[['f'+str(i) for i in range(400)]].values.tolist()\n",
    "Y = data['label'].values.tolist()\n",
    "\n",
    "r_val = randint(1,1000)\n",
    "print('Random state: %d'%(r_val))\n",
    "X_train, X_test, Y_train, Y_test = tts(X,Y,test_size=0.3,random_state=r_val)\n",
    "# 100\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "encoded_train_labels = encoder.transform(Y_train)\n",
    "dummy_train_labels = np_utils.to_categorical(encoded_train_labels)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_test)\n",
    "encoded_test_labels = encoder.transform(Y_test)\n",
    "dummy_test_labels = np_utils.to_categorical(encoded_test_labels)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=400, activation='relu', name='h1'))\n",
    "model.add(Dense(500, activation='relu', name='h3'))\n",
    "model.add(Dense(33, activation='softmax', name='op'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train,dummy_train_labels,epochs=7,batch_size=32,verbose=1,validation_split=0.3)\n",
    "\n",
    "score = model.evaluate(X_test,dummy_test_labels)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state = 313\n",
      "Accuracy: 99.303%\n",
      "Approximate incorrect samples: 40/5880\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from random import randint\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = data[['f'+str(i) for i in range(400)]].values\n",
    "Y = data['label'].values\n",
    "\n",
    "r_val = randint(1,1000)\n",
    "print('Random state = %3d'%(r_val))\n",
    "X_train, X_test, Y_train, Y_test = tts(X,Y,test_size=0.3, random_state=351)\n",
    "\n",
    "print('Training...',end='\\r')\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "print('Testing....',end='\\r')\n",
    "acc = classifier.score(X_test,Y_test)\n",
    "print('Accuracy: %.3f%' % (acc*100))\n",
    "print('Approximate incorrect samples: %d/%d'%((1-acc)*len(X_test),len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state = 228\n",
      "Accuracy: 98.759%\n",
      "Approximate incorrect samples: 73/5880\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = data[['f'+str(i) for i in range(400)]].values\n",
    "Y = data['label'].values\n",
    "\n",
    "r_val = randint(1,1000)\n",
    "print('Random state = %3d'%(r_val))\n",
    "X_train, X_test, Y_train, Y_test = tts(X,Y,test_size=0.3, random_state=r_val)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100, max_depth=800, random_state=r_val, warm_start=True, max_features='log2')\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "acc = classifier.score(X_test,Y_test)\n",
    "print('Accuracy: %.3f%%' % (acc*100))\n",
    "print('Approximate incorrect samples: %d/%d'%((1-acc)*len(X_test),len(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand sign classification\n",
    "### The method of fragmentation\n",
    "\n",
    "The image is divided into blocks of 20x20. In each block, we calculate the area of contour lying in that block and divide it by the area of that block. If there is no contour, the area is simply zero.\n",
    "\n",
    "This calculation is performed 400 times and we get 400 features for a single image. \n",
    "\n",
    "These features are now trained using the classifiers:\n",
    "* Deep Learning Neural Network\n",
    "* KNN\n",
    "* Random Forest\n",
    "* SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data parsed: 19599\n",
      "Data loaded. You may now start classification.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from random import randint\n",
    "\n",
    "data = pd.read_csv('digits_and_letters.csv')\n",
    "print('Total data parsed: %d'%(len(data)))\n",
    "\n",
    "no_of_classes = 36\n",
    "label_indexes = {}\n",
    "for i in range(10): label_indexes[i] = str(i)\n",
    "for i in range(26):\n",
    "    if not chr(ord('a')+i) in ['h','j','v']: label_indexes[10+i] = chr(ord('a')+i)\n",
    "print('Data loaded. You may now start classification.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 15\n",
      "Train on 9603 samples, validate on 4116 samples\n",
      "Epoch 1/12\n",
      "9603/9603 [==============================] - 10s 991us/step - loss: 0.4767 - acc: 0.8717 - val_loss: 0.1492 - val_acc: 0.9602\n",
      "Epoch 2/12\n",
      "9603/9603 [==============================] - 9s 907us/step - loss: 0.0981 - acc: 0.9702 - val_loss: 0.1910 - val_acc: 0.9395\n",
      "Epoch 3/12\n",
      "9603/9603 [==============================] - 9s 926us/step - loss: 0.0692 - acc: 0.9801 - val_loss: 0.0470 - val_acc: 0.9854\n",
      "Epoch 4/12\n",
      "9603/9603 [==============================] - 11s 1ms/step - loss: 0.0384 - acc: 0.9879 - val_loss: 0.1021 - val_acc: 0.9735\n",
      "Epoch 5/12\n",
      "9603/9603 [==============================] - 9s 915us/step - loss: 0.0274 - acc: 0.9918 - val_loss: 0.0648 - val_acc: 0.9776\n",
      "Epoch 6/12\n",
      "9603/9603 [==============================] - 11s 1ms/step - loss: 0.0254 - acc: 0.9931 - val_loss: 0.0602 - val_acc: 0.9818\n",
      "Epoch 7/12\n",
      "9603/9603 [==============================] - 11s 1ms/step - loss: 0.0233 - acc: 0.9934 - val_loss: 0.0615 - val_acc: 0.9866\n",
      "Epoch 8/12\n",
      "9603/9603 [==============================] - 10s 1ms/step - loss: 0.0388 - acc: 0.9884 - val_loss: 0.0634 - val_acc: 0.9847\n",
      "Epoch 9/12\n",
      "9603/9603 [==============================] - 9s 932us/step - loss: 0.0221 - acc: 0.9939 - val_loss: 0.1011 - val_acc: 0.9735\n",
      "Epoch 10/12\n",
      "9603/9603 [==============================] - 11s 1ms/step - loss: 0.0204 - acc: 0.9934 - val_loss: 0.0442 - val_acc: 0.9900\n",
      "Epoch 11/12\n",
      "9603/9603 [==============================] - 11s 1ms/step - loss: 0.0292 - acc: 0.9918 - val_loss: 0.0442 - val_acc: 0.9883\n",
      "Epoch 12/12\n",
      "9603/9603 [==============================] - 13s 1ms/step - loss: 0.0148 - acc: 0.9965 - val_loss: 0.0320 - val_acc: 0.9934\n",
      "5880/5880 [==============================] - 1s 134us/step\n",
      "\n",
      "acc: 99.49%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.utils import np_utils\n",
    "\n",
    "X = data[['f'+str(i) for i in range(400)]].values.tolist()\n",
    "Y = data['label'].values.tolist()\n",
    "\n",
    "r_val = randint(1,1000)\n",
    "print('Random state: %d'%(r_val))\n",
    "X_train, X_test, Y_train, Y_test = tts(X,Y,test_size=0.3,random_state=r_val)\n",
    "# 15\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "encoded_train_labels = encoder.transform(Y_train)\n",
    "dummy_train_labels = np_utils.to_categorical(encoded_train_labels)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_test)\n",
    "encoded_test_labels = encoder.transform(Y_test)\n",
    "dummy_test_labels = np_utils.to_categorical(encoded_test_labels)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(700, input_dim=400, activation='relu', name='h1'))\n",
    "model.add(Dense(500, activation='relu', name='h2'))\n",
    "model.add(Dense(200, activation='relu',name='h3'))\n",
    "model.add(Dense(33, activation='softmax', name='op'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train,dummy_train_labels,epochs=12,batch_size=32,verbose=1,validation_split=0.3)\n",
    "\n",
    "score = model.evaluate(X_test,dummy_test_labels)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "\n",
    "to_be_saved_model = model.to_json()\n",
    "with open('deep_fragmented_hand_sign_classifier.json','w') as model_file: model_file.write(to_be_saved_model)\n",
    "model.save_weights('deep_fragmented_hand_sign_classifier_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state = 167\n",
      "Accuracy: 99.541%\n",
      "Approximate incorrect samples: 26/5880\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from random import randint\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "\n",
    "X = data[['f'+str(i) for i in range(400)]].values\n",
    "Y = data['label'].values\n",
    "\n",
    "r_val = randint(1,1000)\n",
    "print('Random state = %3d'%(r_val))\n",
    "X_train, X_test, Y_train, Y_test = tts(X,Y,test_size=0.3, random_state=164)\n",
    "# 563, 164\n",
    "\n",
    "print('Adding data...',end='\\r')\n",
    "classifier = KNeighborsClassifier(n_neighbors=4)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "print('Testing...    ',end='\\r')\n",
    "acc = classifier.score(X_test,Y_test)\n",
    "print('Accuracy: %.3f%%' % (acc*100))\n",
    "print('Approximate incorrect samples: %d/%d'%((1-acc)*len(X_test),len(X_test)))\n",
    "\n",
    "classifier.fit(X_test, Y_test)\n",
    "pickle.dump(classifier, open('digits_and_letters_model_new.sav','wb'))\n",
    "print('Model saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state = 682\n",
      "Accuracy: 99.252%\n",
      "Approximate incorrect samples: 44/5880\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = data[['f'+str(i) for i in range(400)]].values\n",
    "Y = data['label'].values\n",
    "\n",
    "r_val = randint(1,1000)\n",
    "print('Random state = %3d'%(r_val))\n",
    "X_train, X_test, Y_train, Y_test = tts(X,Y,test_size=0.3, random_state=r_val)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100, max_depth=800, random_state=r_val, warm_start=True, max_features='log2')\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "acc = classifier.score(X_test,Y_test)\n",
    "print('Accuracy: %.3f%%' % (acc*100))\n",
    "print('Approximate incorrect samples: %d/%d'%((1-acc)*len(X_test),len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state = 876\n",
      "Accuracy: 97.143%\n",
      "Approximate incorrect samples: 168/5880\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X = data[['f'+str(i) for i in range(400)]].values\n",
    "Y = data['label'].values\n",
    "\n",
    "r_val = randint(1,1000)\n",
    "print('Random state = %3d'%(r_val))\n",
    "X_train, X_test, Y_train, Y_test = tts(X,Y,test_size=0.3, random_state=r_val)\n",
    "\n",
    "classifier = SVC(random_state=r_val)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "acc = classifier.score(X_test,Y_test)\n",
    "print('Accuracy: %.3f%%' % (acc*100))\n",
    "print('Approximate incorrect samples: %d/%d'%((1-acc)*len(X_test),len(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPredictions(model,X_test):\n",
    "    from numpy import array\n",
    "    preds=model.predict(array(X_test))\n",
    "    y_pred=[]\n",
    "    for row in preds:\n",
    "        if row[0]>row[1]:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from __future__ import division\n",
    "# Function for evaluating score of the tree\n",
    "def evaluate_score(clf,X,Y):\n",
    "    Y_predicted=list(map(int,(clf.predict(X)).tolist()))\n",
    "    correct_predicts=0\n",
    "    for i in range(0,len(Y)):\n",
    "        if Y[i]==Y_predicted[i]:\n",
    "            correct_predicts=correct_predicts+1\n",
    "    acc=(correct_predicts/len(X))*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getModelStats(Y_test,Y_test_pred):\n",
    "    true_pos,false_pos,false_neg,true_neg=0,0,0,0\n",
    "    pos,neg=0,0\n",
    "    for i in range(len(Y_test)):\n",
    "        if Y_test[i]==0:\n",
    "            pos+=1\n",
    "        else:\n",
    "            neg+=1\n",
    "        if Y_test[i]==Y_test_pred[i]:\n",
    "            if Y_test[i]==0:\n",
    "                true_pos+=1\n",
    "            else:\n",
    "                true_neg+=1\n",
    "        else:\n",
    "            if Y_test[i]==0:\n",
    "                false_neg+=1\n",
    "            else:\n",
    "                false_pos+=1\n",
    "    print(\"Total number of positives in the set:\"+str(pos))\n",
    "    print(\"Total number of negatives in the set:\"+str(neg))\n",
    "    print(\"True Positive:\"+str(true_pos))\n",
    "    print(\"False Positive:\"+str(false_pos))\n",
    "    print(\"False Negative:\"+str(false_neg))\n",
    "    print(\"True Negative:\"+str(true_neg))\n",
    "    # Model statistics:\n",
    "    sensitivity=(true_pos/pos)\n",
    "    print(\"Model sensitivity is %0.4f\" %sensitivity)\n",
    "    specificity=(true_neg/neg)\n",
    "    print(\"Model specificity is %0.4f\" %specificity)\n",
    "    precision=true_pos/(true_pos+false_pos)\n",
    "    print(\"Model precision is %0.4f\" %precision)\n",
    "    f1_score=(2*true_pos)/(2*true_pos+false_pos+false_neg)\n",
    "    print(\"Model F1 score is %0.4f\" %f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples loaded:209740\n",
      "Number of test samples loaded:89889\n"
     ]
    }
   ],
   "source": [
    "# Loading the file\n",
    "X_train=[]\n",
    "Y_train=[]\n",
    "input_file=open(\"skin-detection-training.txt\",\"r\")\n",
    "for line in input_file:\n",
    "    attrs=line.split(\",\")\n",
    "    Y_train.append(int(attrs[-1].strip()))\n",
    "    X_train.append(list(map(float,attrs[0:3])))\n",
    "print(\"Number of training samples loaded:\"+str(len(X_train)))\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "input_file=open(\"skin-detection-testing.txt\",\"r\")\n",
    "for line in input_file:\n",
    "    attrs=line.split(\",\")\n",
    "    Y_test.append(int(attrs[-1].strip()))\n",
    "    X_test.append(list(map(float,attrs[0:3])))\n",
    "print(\"Number of test samples loaded:\"+str(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 188766 samples, validate on 20974 samples\n",
      "Epoch 1/12\n",
      "188766/188766 [==============================] - 13s 68us/step - loss: 0.5067 - acc: 0.7621 - val_loss: 0.5009 - val_acc: 0.7610\n",
      "Epoch 2/12\n",
      "188766/188766 [==============================] - 10s 54us/step - loss: 0.5000 - acc: 0.7623 - val_loss: 0.5003 - val_acc: 0.7610\n",
      "Epoch 3/12\n",
      " 65031/188766 [=========>....................] - ETA: 6s - loss: 0.4991 - acc: 0.7623"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-d8aed479d15f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m# Compile model & fit data to model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mmodel_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdummy_train_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m53\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1657\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1202\u001b[0m                             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1204\u001b[1;33m                             \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1205\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m                         raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ROC for keras model:\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "enc_Y_train = encoder.transform(Y_train)\n",
    "dummy_train_labels = np_utils.to_categorical(enc_Y_train)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_test)\n",
    "enc_Y_test = encoder.transform(Y_test)\n",
    "dummy_test_labels = np_utils.to_categorical(enc_Y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(3,input_dim=3,activation='relu', name='input_layer'))\n",
    "model.add(Dense(120,activation='relu', name='hidden_layer_1'))\n",
    "model.add(Dense(80,activation='relu', name='hidden_layer_2'))\n",
    "model.add(Dense(40,activation='relu', name='hidden_layer_3'))\n",
    "model.add(Dense(20,activation='relu', name='hidden_layer_4'))\n",
    "model.add(Dense(2, activation='softmax', name='output_layer'))\n",
    "\n",
    "# Compile model & fit data to model.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_history=model.fit(X_train,dummy_train_labels,batch_size=53,epochs=12,verbose=1,validation_split=0.1)\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()\n",
    "Y_test_pred=getPredictions(model,X_test)\n",
    "Y_train_pred=getPredictions(model,X_train)\n",
    "corrects=0\n",
    "for i in range(len(Y_test)):\n",
    "    if Y_test[i]==Y_test_pred[i]:\n",
    "        corrects+=1\n",
    "test_acc=(corrects/len(Y_test))*100\n",
    "print(\"Testing accuracy: %0.4f\" %test_acc)\n",
    "corrects=0\n",
    "for i in range(len(Y_train)):\n",
    "    if Y_train[i]==Y_train_pred[i]:\n",
    "        corrects+=1\n",
    "train_acc=(corrects/len(Y_train))*100\n",
    "print(\"Training accuracy: %0.4f\" %train_acc)\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "import matplotlib.pyplot as plt\n",
    "fpr,tpr,_=roc_curve(Y_test,Y_test_pred,pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "# From here is where the graph is operated. Above this the entire calculation is for finding the False Positive Rate, True Positive Rate and the Area Under Curve\n",
    "plt.title('ROC for Neural Network')\n",
    "lw=2\n",
    "plt.plot(fpr, tpr, color='blue', label='Area = %0.4f' %roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "# Developing the Confusion Matrix:\n",
    "getModelStats(Y_test,Y_test_pred)\n",
    "# print('Saving model....\\r',end='')\n",
    "# to_be_saved_model = model.to_json()\n",
    "# with open('model1.json','w') as model_file: model_file.write(to_be_saved_model)\n",
    "# model.save_weights('weights1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:98.79755888242586\n",
      "Accuracy on test set:96.3310304931638\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ac8bbadeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of positives in the set:21078\n",
      "Total number of negatives in the set:68811\n",
      "True Positive:19619\n",
      "False Positive:1839\n",
      "False Negative:1459\n",
      "True Negative:66972\n",
      "Model sensitivity is 0.9308\n",
      "Model specificity is 0.9733\n",
      "Model precision is 0.9143\n",
      "Model F1 score is 0.9225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree fitting:\n",
    "from sklearn import tree\n",
    "classifier=tree.DecisionTreeClassifier()\n",
    "classifier.fit(X_train,Y_train)\n",
    "train_score=evaluate_score(classifier,X_train,Y_train)\n",
    "print(\"Accuracy on training set:\"+str(train_score))\n",
    "test_score=evaluate_score(classifier,X_test,Y_test)\n",
    "print(\"Accuracy on test set:\"+str(test_score))\n",
    "# Plotting the ROC curve and finding the AuC:\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "import matplotlib.pyplot as plt\n",
    "Y_test_preds=list(map(int,(classifier.predict(X_test)).tolist()))\n",
    "fpr,tpr,_=roc_curve(Y_test,Y_test_preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "# From here is where the graph is operated. Above this the entire calculation is for finding the False Positive Rate, True Positive Rate and the Area Under Curve\n",
    "plt.title('ROC for Decision Tree')\n",
    "lw=2\n",
    "plt.plot(fpr, tpr, color='blue', label='Area = %0.4f' %roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "getModelStats(Y_test,Y_test_preds)\n",
    "import graphviz\n",
    "dot_data = tree.export_graphviz(classifier, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

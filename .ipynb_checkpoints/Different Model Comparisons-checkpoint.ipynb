{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft, ifft\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the dataframe:\n",
    "dataframe = pd.read_csv(\"data.csv\", header=None)\n",
    "dataframe.head(10)\n",
    "Y=dataframe[10]\n",
    "Y=Y.values\n",
    "del dataframe[10]\n",
    "X=dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-923b99a0cfdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdataops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnew_X_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mper_sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnew_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_X_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mnew_Y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_X_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmain_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "per_sample=200\n",
    "dataops=[1,2,3,4,5,6,7,8]\n",
    "new_X_len=len(dataops)*per_sample\n",
    "new_X=np.zeros(shape=(new_X_len,10))\n",
    "new_Y=np.zeros(shape=(new_X_len,1))\n",
    "main_index=0\n",
    "for i in range(len(dataops)):\n",
    "    temp_data=[]\n",
    "    for j in range(len(Y)):\n",
    "        if Y[j]==dataops[i]:\n",
    "            temp_data.append(X[j])\n",
    "    used_samples=0\n",
    "    while used_samples<per_sample:\n",
    "        index_chosen=randint(0,len(temp_data)-1)\n",
    "        new_X[main_index]=temp_data[index_chosen]\n",
    "        new_Y[main_index]=dataops[i]\n",
    "        main_index+=1\n",
    "        used_samples+=1\n",
    "print(new_X[0:10])\n",
    "print(new_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:100.0\n",
      "Accuracy on testing set:28.9719626168\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "trainData_S,testData_S,trainData_L,testData_L = train_test_split(X,Y,test_size = 0.33,random_state=42)\n",
    "svm=SVC(C=10,gamma='auto',decision_function_shape='ovo')\n",
    "svm.fit(trainData_S,trainData_L)\n",
    "print(\"Accuracy on training set:\"+str(svm.score(trainData_S,trainData_L)*100))\n",
    "print(\"Accuracy on testing set:\"+str(svm.score(testData_S,testData_L)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:88.8888888889\n",
      "Accuracy on testing set:77.5700934579\n"
     ]
    }
   ],
   "source": [
    "#k-NN\n",
    "trainData_S,testData_S,trainData_L,testData_L = train_test_split(X,Y,test_size = 0.33,random_state=42)\n",
    "neigh = KNeighborsClassifier(n_neighbors = 5)\n",
    "neigh.fit(trainData_S,trainData_L)\n",
    "print(\"Accuracy on training set:\"+str(neigh.score(trainData_S,trainData_L)*100))\n",
    "print(\"Accuracy on testing set:\"+str(neigh.score(testData_S,testData_L)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/214 [===>..........................] - ETA: 3s\n",
      "Accuracy on Training set: 100.00%\n",
      " 32/106 [========>.....................] - ETA: 0s\n",
      "Accuracy on Testing set: 81.13%\n"
     ]
    }
   ],
   "source": [
    "#Keras model\n",
    "X1,X2,Y1,Y2 = train_test_split(X,Y,test_size = 0.33,random_state=42)\n",
    "train_x=X1.values\n",
    "train_y=Y1.values\n",
    "test_x=X2.values\n",
    "test_y=Y2.values\n",
    "# One-Hot encoding\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_y)\n",
    "encoded_train_Y = encoder.transform(train_y)\n",
    "dummy_train_y = np_utils.to_categorical(encoded_train_Y)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(test_y)\n",
    "encoded_test_Y = encoder.transform(test_y)\n",
    "dummy_test_y = np_utils.to_categorical(encoded_test_Y)\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=10, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_x,dummy_train_y,epochs=150,batch_size=28,verbose=0)\n",
    "scores = model.evaluate(train_x,dummy_train_y)\n",
    "print(\"\\n%s: %.2f%%\" % (\"Accuracy on Training set\", scores[1]*100))\n",
    "scores = model.evaluate(test_x,dummy_test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (\"Accuracy on Testing set\", scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
